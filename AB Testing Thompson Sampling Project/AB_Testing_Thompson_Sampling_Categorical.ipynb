{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnKxXCMVLKlJ"
      },
      "source": [
        "# From the course: Bayesin Machine Learning in Python: A/B Testing\n",
        "# https://deeplearningcourses.com/c/bayesian-machine-learning-in-python-ab-testing\n",
        "# https://www.udemy.com/bayesian-machine-learning-in-python-ab-testing\n",
        "\n",
        "from __future__ import print_function, division\n",
        "from builtins import range\n",
        "\n",
        "# Note: you may need to update your version of future\n",
        "# sudo pip install -U future\n",
        "\n",
        "# Thompson Sampling Categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efvuzcFNLxmy"
      },
      "source": [
        "np.random.seed(2)\n",
        "\n",
        "# Custmer Input Meta Data\n",
        "\n",
        "# Input the name of the experiment\n",
        "\n",
        "experiment_title = ['To Find The Best Set Among 3 Sets of 6 Product Photos in the Web Page']\n",
        "\n",
        "# Input the number of trials for the experiment\n",
        "\n",
        "NUM_TRIALS = 10000\n",
        "\n",
        "# Input the \"real\" probabilities for the test options in the simulation of the experiment\n",
        "\n",
        "BANDIT_PROBABILITIES = [[0.2, 0.1, 0.1, 0.2, 0.2, 0.2], [0.5, 0.1, 0.1, 0.1, 0.1, 0.1], [0.3, 0.1, 0.1, 0.3, 0.1, 0.1]]\n",
        "\n",
        "# Input the decision criteria\n",
        "\n",
        "decision_criterion = ['reward generated']\n",
        "\n",
        "# Input the \"reward\" of each user selection in the test options\n",
        "\n",
        "reward_index = np.array([1, 2, 3, 4, 5, 6])\n",
        "#How much money per click\n",
        "reward_value = np.array([0, 399, 489, 599, 428, 528])\n",
        "\n",
        "# Calculate the expected rewards for each test option\n",
        "\n",
        "dice_expected_reward_list = [np.average(reward_value, weights = dice_prob) * NUM_TRIALS for dice_prob in BANDIT_PROBABILITIES]\n",
        "\n",
        "reward_optimal = np.max(dice_expected_reward_list)\n",
        "reward_lowest = np.min(dice_expected_reward_list)\n",
        "reward_avg = np.average(dice_expected_reward_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy7sLAfjMD2L"
      },
      "source": [
        "class Bandit:\n",
        "  def __init__(self, p, alpha=[1,1,1,1,1,1]):\n",
        "    self.p = p\n",
        "    self.alpha = alpha\n",
        "    self.N = 0 # for information only\n",
        "\n",
        "  def pull(self):\n",
        "    return np.random.choice(reward_index, size=1, p=np.array(self.p))\n",
        "\n",
        "  def sample(self):\n",
        "    s = np.random.dirichlet(self.alpha, 1)\n",
        "    a = np.average(s[0], weights=reward_value)\n",
        "    return a\n",
        "\n",
        "  def update(self, x):\n",
        "    self.alpha += x\n",
        "    self.N += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhJ-mvalYPv0",
        "outputId": "02f1f118-c838-4557-8b7c-8d99f39c4e9b"
      },
      "source": [
        "def experiment():\n",
        "  bandits = [Bandit(p) for p in BANDIT_PROBABILITIES]\n",
        "  print(bandits)\n",
        "\n",
        "  sample_points = [1,2,3,4,5,1000,5000,10000]\n",
        "  rewards = np.zeros(NUM_TRIALS)\n",
        "\n",
        "  c =np.array([0, 0, 0, 0, 0, 0])\n",
        "\n",
        "  for i in range(NUM_TRIALS):\n",
        "    j = np.argmax([b.sample() for b in bandits]) # Take samples from Dirichlet\n",
        "\n",
        "    x = bandits[j].pull() # Select an arm and check the reward\n",
        "    rewards[i] = reward_value[x[0]-1]\n",
        "    c[x[0]-1] = 1\n",
        "    bandits[j].update(c)\n",
        "\n",
        "    c =np.array([0, 0, 0, 0, 0, 0])\n",
        "\n",
        "    if i in sample_points:\n",
        "      print(f'{i}th iteration, select test option {j+1}, received award {rewards[i]}')\n",
        "\n",
        "  # Print the customer input meta data\n",
        "\n",
        "  print('\\n**************Customer Inpurt Meta Data***************\\n')\n",
        "\n",
        "  print(f'Experiment Description: {experiment_title}\\n')\n",
        "  print(f'The number of trials for the experiment is: {NUM_TRIALS}\\n')\n",
        "  print(f'The metric used in the experiment is: {decision_criterion}\\n')\n",
        "  print(f'There are {len(BANDIT_PROBABILITIES)} test options and based on the simulation probabilities:')\n",
        "  #print('Based on the probabilities and vales provided in this simulation, the expected value for each test option is as follows: ')\n",
        "  #print(f'The expected rewards for test option 1 is: ${int(dice_expected_reward_list[0])} if only Test Option 1 is used')\n",
        "  #print(f'The expected rewards for test option 2 is: ${int(dice_expected_reward_list[1])} if only Test Option 2 is used')\n",
        "  #print(f'The expected rewards for test option 3 is: ${int(dice_expected_reward_list[2])} if only Test Option 3 is used\\n')\n",
        "\n",
        "  print(f\"The highest expected total rewards is from test option {np.argmax(dice_expected_reward_list)+1}: ${round(reward_optimal,2)}\")\n",
        "  print(f\"The lowest expected total rewards is from test option {np.argmin(dice_expected_reward_list)+1}: ${round(reward_lowest,2)}\\n\")\n",
        "  print(f\"The average expected total rewards from the traditinal statistical method is: ${int(reward_avg)}\\n\")\n",
        "\n",
        "  print('**************Experiment Results**********************\\n')\n",
        "\n",
        "  print(f\"total reward earned from the experiment with Bayesian Machine Learning: ${int(rewards.sum())}\\n\")\n",
        "  print(f\"overall win rate from the experiment: {rewards.sum() / NUM_TRIALS}\\n\")\n",
        "  print(f\"num times selected each test option: {[b.N for b in bandits]}\\n\")\n",
        "\n",
        "  print('**************Experiment Result Analysis***************\\n')\n",
        "  print(f\"difference between the Bayesian and traditional statistical approches is: ${int(rewards.sum())-int(reward_avg)}\\n\")\n",
        "  print(f\"difference between the Bayesian and highest expected rewards is: ${int(reward_optimal)-int(rewards.sum())}\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  experiment()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<__main__.Bandit object at 0x7f8084e54b10>, <__main__.Bandit object at 0x7f8084e54ed0>, <__main__.Bandit object at 0x7f8084e54210>]\n",
            "1th iteration, select test option 1, received award 428.0\n",
            "2th iteration, select test option 2, received award 0.0\n",
            "3th iteration, select test option 1, received award 599.0\n",
            "4th iteration, select test option 1, received award 599.0\n",
            "5th iteration, select test option 1, received award 599.0\n",
            "1000th iteration, select test option 1, received award 0.0\n",
            "5000th iteration, select test option 1, received award 489.0\n",
            "\n",
            "**************Customer Inpurt Meta Data***************\n",
            "\n",
            "Experiment Description: ['To Find The Best Set Among 3 Sets of 6 Product Photos in the Web Page']\n",
            "\n",
            "The number of trials for the experiment is: 10000\n",
            "\n",
            "The metric used in the experiment is: ['reward generated']\n",
            "\n",
            "There are 3 test options and based on the simulation probabilities:\n",
            "The highest expected total rewards is from test option 1: $3998000.0\n",
            "The lowest expected total rewards is from test option 2: $2443000.0\n",
            "\n",
            "The average expected total rewards from the traditinal statistical method is: $3360666\n",
            "\n",
            "**************Experiment Results**********************\n",
            "\n",
            "total reward earned from the experiment with Bayesian Machine Learning: $3959087\n",
            "\n",
            "overall win rate from the experiment: 395.9087\n",
            "\n",
            "num times selected each test option: [9709, 36, 255]\n",
            "\n",
            "**************Experiment Result Analysis***************\n",
            "\n",
            "difference between the Bayesian and traditional statistical approches is: $598421\n",
            "\n",
            "difference between the Bayesian and highest expected rewards is: $38913\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh2f0TX8T4ER"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOUDegRkT4Iv"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj3uN5wTT4KI"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}